    //depth = 0
    //prompt user to enter a root url and a depth_limit >= 1

    //Push root url and depth of 0 into queue

    //while depth <= depth_limit && queue not empty
      
        //Pop url from front of queue
        //Set depth to depth associated with url --> necessary for backtracking up the tree of urls
        //save HTML of url in txt file
        //perform character extraction of txt file and save data in a vector
        
        //int children = 0
        //if depth < depth_limit
         //children = find_children(url)
        
        //if children > 0
          //for (i = 0; i < children; i++)
           // push unseen children with depth++ onto queue
          
          
          *** must keep track of each url's depth
        
       
                 

